{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2dd0607",
   "metadata": {},
   "source": [
    "# Домашнее задание 2 (60 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc69c4",
   "metadata": {},
   "source": [
    "## Задача 1 (25 pts)\n",
    "## PLU разложение\n",
    "\n",
    "- (5 pts) Докажите, что LU разложение существует iff матрица является строго регулярной.\n",
    "- (15 pts) Поскольку не все матрицы являются строго регулярными, необходимо осуществлять перестановки элементов в строке так, чтобы на диагонали оказался как можно больший по модулю элемент. Это повышает устойчивость процедуры исключения переменных и накопления треугольных факторов. Реализуйте алгоритм вычисления PLU разложения. При этом\n",
    "    - перестановок столбцов достаточно, хотя если вы реализуете алгоритм для PLUQ разложения, то есть будут переставляться и строки и столбцы, то получите бонусные баллы\n",
    "    - перестановку и обратную к ней необходимо хранить как одномерные массивы. Вам понадобится реализовать функцию для инкрементального обновления пеерстановки после перехода к следующему диагональному элементу.\n",
    "    - в качестве опорного элемента достаточно использовать максимальный по модулю элемент в строке\n",
    "    - не забудьте максимально возможным образом использовать возможности NumPy и исключить циклы там где это возможно  \n",
    "- (5 pts) Сравните результат работы вашего алгоритма с методом из ```scipy.linalg``` для плохо обусловленной матрицы. Постройте график зависимости работы вашего алгоритма от размерности матрицы, подтверждается ли асимптотика для PLU разложения?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8db916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Место для вашего решения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc808e",
   "metadata": {},
   "source": [
    "## Задача 2 (35 pts)\n",
    "\n",
    "## Ускорение Андерсена\n",
    "\n",
    "Многие итерационные методы в вычислительной линейной алгебре могут быть записаны в форме итерации неподвижной точки\n",
    "\n",
    "$$ x_{k+1} = f(x_k), $$\n",
    "\n",
    "так что решение задачи удовлетворяет условию $x^* = f(x^*)$. Достаточным условием сходимости такого итерационного процесса для функции $f$ является её Липшецевость с константой $L < 1$ и непрерывная дифференцируемость в окрестности $x^*$  так что $|f'(x^*)| < L$. \n",
    "Вокруг итераций такого типа существует довольно много разнообразной теории, но нас будет интересовать специальный способ ускорения сходимости такого итерационного процесса под названием **ускорение Андерсена**. \n",
    "Основная идея метода в представлении следующего приближения как линейной комбинации нескольких предыдущих значений функции $f$, более формально\n",
    "\n",
    "$$ x_{k+1} = \\sum_{i=0}^{m-1} \\alpha_i f(x_{k-m+i}), $$\n",
    "\n",
    "где $m$ - это размер истории, который необходимо хранить и который задаётся до запуска метода, и $\\alpha \\in \\mathbb{R}^n$ ищется как решение следующей задачи оптимизации\n",
    "\n",
    "$$ \\min_{\\alpha} \\| R\\alpha\\|_2, \\quad \\text{subject to} \\quad \\sum_{i=0}^{m-1} \\alpha_i = 1, $$\n",
    "\n",
    "где $R = [r_0, \\ldots, r_{m-1}]$ и $r_i = f(x_i) - x_i$ вектора невязок.\n",
    "Отметим, что при $m=1$ мы получим исходную итерацию неподвижной точки.\n",
    "\n",
    "Заметим, что задача поиска коэффициентов $\\alpha_i$ очень похожа на стандартную задачу наименьших квадратов, которую можно решить с помощью функции ```np.linalg.lstsq```, но присутствует дополнительное нормировочное ограничение на коэффициенты. \n",
    "\n",
    "- Придумайте, как равносильно преобразовать задачу к виду, который позволит получить решение с помощью функции ```np.linalg.lstsq```.\n",
    "- Сравните получаемый ответ на случайных данных (матрица $R$) с решением исходной задачи, полученным с помощью функции ```scipy.optimize.minimize```.\n",
    "\n",
    "### Степенной метод (10 pts)\n",
    "\n",
    "- Запишите степенной метод в виде итерации неподвижной точки. Чему равна функция $f$?\n",
    "- Реализуйте ускорение Андерсена для степенного метода с использованием подхода к решению вспомогательной задачи на коэффициенты $\\alpha$, полученным выше. Cравните сходимости обычного и ускоренного степенного метода по времени и числу итераций? Рассмотрите различные значения для размера истории и проанализируйте влияние этого гиперпараметра на скорость сходимости (по времени и по числу итераций) \n",
    "\n",
    "### Неотрицательное матричное разложение (20 pts)\n",
    "\n",
    "Задача неотрицательного матричного разложения заключается в поиске разложения данной матрицы на факторы с неотрицательными компонентами, то есть решение следующей задачи оптимизации\n",
    "\n",
    "$$ \\min_{W \\geq 0, H \\geq 0} \\|X - WH\\|_F^2, $$\n",
    "\n",
    "где $X \\in \\mathbb{R}^{m \\times n}$, $W \\in \\mathbb{R}^{m \\times k}$ и $H \\in \\mathbb{R}^{k \\times n}$, так что $k < n$. Известно что такая задача является NP-полной, но существуют различные подходы к её приближённому решению. Одним из таких подходов является идея **попеременной оптимизации**, в которой по очереди фиксируются матрицы $W^{(k)}$ и $H^{(k)}$ и обновляются матрицы $H$ и $W$ соответственно. Так как при фиксированной одной матрице задача становится очень похожа на задачу линейных наименьших квадратов, но с дополнительным ограничением неотрицательности на искомую матрицу.\n",
    "\n",
    "- Реализуйте наивный алгориитм приближённого решения задачи неотрицательного матричного разложения на основе попеременной оптимизации. Для получения решения всмомогательных задач можно проецировать результат решения линейной задачи наименьших квадратов на множество матриц с неотрицательными элементами. Это делается простым занулением отрицательных элементов, что надеюсь очевидно для вас. Существуют [другие подходы](https://arxiv.org/pdf/1401.5226.pdf) к получению промежуточных значений для матриц $W^{(k)}$ и $H^{(k)}$, которые вы можете протестировать, если выше описанная стратегия не будет сходиться. \n",
    "\n",
    "\n",
    "- Одну итерацию обновления матриц $(W, H)$ можно представить как итерацию неподвижной точки вида \n",
    "\n",
    "$$(W^{(k+1)}, H^{(k+1)}) = F(W^{(k)}, H^{(k)}), $$\n",
    "\n",
    "где внутри $F$ спрятаны решения вспомогательных задач оптимизации. А значит реализованный вами выше метод можно ускорить с помощью ускорения Андерсена. Реализуйте ускоренный таким образом метод приближённого решения задачи неотрицательного матричного разложения.\n",
    "\n",
    "- Рассмотрите задачу тематического моделирования, то есть разбиения документов по темам на основе слов, которые в документах используются. Эту задачу можно формализовать с помощью неотрицательного матричного разложения матрицы \"слов-документов\", элемент $(i, j)$ которой равен 1 если $i$-ое слово используется в $j$-ом документе. Это самый простой способ представления текстовых документов в виде пригодном для их анализа методами вычислительной линейной алгебры. Можно протестировать чуть более продвинутый способ представления слов и документов под названием tf-idf, подробности [тут](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Для построения матрицы $X$ используйте тестовый датасет [20newsgroup](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups). В контексте этого приложения параметр $k$ - это число тем, матрица $W$ содержит распределение слов по темам, а матрица $H$ коэффициенты разложения каждого документа по темам. Так как все элементы матриц неотрицательны, мы можем интерпретировать их как веса и доли, что упрощает интерпретацию результатов в рамках выбранной предметной области. Сравните на этих данных сходимость базовой и ускоренной реализации метода приближённого решения задачи неотрицательного матричного разложения (по времени и по итерациям). Прокомментируйте полученные результаты. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e3cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Место для вашего решения"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
